#!/usr/bin/env python
import glob
import sys
from os.path import join
import os
from torch.utils.data import Dataset, DataLoader, TensorDataset
import imageio
import torch
import torch.nn as nn
import numpy as np
import matplotlib

import viz
from mapping import bit2dec, dec2bit, compare_bitstream

matplotlib.use('Agg')
import config as c

if c.no_cond_net:
    import model_no_cond as model
else:
    import model
import data

# è¿™é‡Œå°±å¯ä»¥åšæ˜ å°„äº†å•ŠğŸ˜€
# def sample_z(N, outputs):
#     sampled_z = []
#     for o in outputs:
#         shape = list(o.shape)
#         shape[0] = N
#         sampled_z.append(torch.randn(shape).cuda())
#     return sampled_z

# def cal_avg_var(z):
#     avg0 = np.average(np.array(z[0].cpu()))
#     avg1 = np.average(np.array(z[1].cpu()))
#     avg2 = np.average(np.array(z[2].cpu()))
#     avg3 = np.average(np.array(z[3].cpu()))
#     avg = (avg0 + avg1 + avg2 + avg3) / 4
#     var = np.var(np.array(z[0].cpu()))
#     return avg, var


# åµŒå…¥

def sample_z(N, outputs, args):
    if args.mapping=='True':
        print('i am mapping, k={}'.format(args.size_k))
        bitstream = ""  # ä¸€ç»´01å­—ç¬¦ä¸²
        map_sampled_z = []  # ä¿æŒå’Œoutputsä¸€æ ·çš„ç»´åº¦ï¼ˆå››éƒ¨åˆ†ç»„æˆï¼‰
        for o in outputs:
            shape = list(o.shape)
            shape[0] = N
            bits, z = bit2dec(shape, size_group=args.size_k, boundary=args.delta, gap=args.g / 2)
            bitstream += bits
            map_sampled_z.append(torch.tensor(z, dtype=torch.float32).cuda())
        return bitstream, map_sampled_z

    if args.mapping=='False':
        sampled_z = []
        for o in outputs:
            shape = list(o.shape)
            shape[0] = N
            sampled_z.append(torch.randn(shape).cuda())
        return "", sampled_z

# æå–
def extract(multi_dim_latent, args):
    bitstream = ""  # ä¸€ç»´01å­—ç¬¦ä¸²
    if args.mapping:
        for noise in multi_dim_latent:
            noise = noise.squeeze().cpu().numpy()
            bits = dec2bit(noise, args.size_k, args.g/2)
            bitstream += bits
    return bitstream

def reconZ_relate2which_jpg_is_small(z, outputs, batch_idx, n, args):
    stego2copy = './output/stego_png/k={}/batch={}/{}.png'

    stego_small_reconZ_dir = './output/stego_png/k={}_small_reconZ/batch={}'.format(args.size_k, batch_idx)
    if not os.path.exists(stego_small_reconZ_dir):
        os.makedirs(stego_small_reconZ_dir)

    copy_dir = './output/stego_png/k={}_small_reconZ/batch={}'

    log_file = './output/stego_png/k={}_small_reconZ/log.txt'.format(args.size_k)
    with open(log_file, 'a') as f:
        for i in range(n):
            dif = 0
            for k in range(4):
                dif += np.sum(abs(np.array(z[k][i].cpu()) - np.array(outputs[k][i].cpu())))
            dif = dif / 8192  # 64*64*2 = 8192
            f.write('batch={}, image_idx={}, reconZ_error={}\n'.format(batch_idx, i, dif))
            if(dif < 1.0e-05):
                cmd = 'cp '+stego2copy.format(args.size_k, batch_idx, i)+' '+copy_dir.format(args.size_k, batch_idx)
                os.system(cmd)

        f.close()


if __name__ == '__main__':
    model_name = c.filename
    model.load(model_name)
    model.combined_model.eval()
    model.combined_model.module.inn.eval()

    if not c.no_cond_net:
        model.combined_model.module.feature_network.eval()
        model.combined_model.module.fc_cond_network.eval()

    ## begin
    import argparse
    parser = argparse.ArgumentParser(description='cINN-based image steganography')
    parser.add_argument('--mapping', type=str, help='map means embed msg')
    parser.add_argument('--size_k', type=int, help='k means size group(capacity)')
    parser.add_argument('--delta', type=float, help='delta means boundary')
    parser.add_argument('--g', type=float, help='g/2 means gap')
    args = parser.parse_args()

    # æ•°æ®Xæ˜¯Labæ ¼å¼çš„
    batch_idx = 0
    for x in data.test_loader:
        with torch.no_grad():
            n = x.shape[0]
            ims = []
            x = x[:n]
            print('-------'*10)
            # åå‘ åµŒå…¥
            # ä¸ºäº†é‡‡æ ·ï¼Œå…ˆé¢„æµ‹Zå½¢çŠ¶
            xl, xab, xcnd, _ = model.prepare_batch(x)
            output_z = model.cinn(xab, xcnd)
            # æŒ‰ç…§output_zçš„å½¢çŠ¶ï¼Œç”ŸæˆNä¸ªæ ·æœ¬
            torch.manual_seed(c.seed)
            ## åµŒå…¥æ¯”ç‰¹æµ
            bitstream1, z = sample_z(N=n, outputs=output_z, args=args)

            print('åå‘ åµŒå…¥ï¼šé‡‡æ ·çš„z[0] dtype is {}:'.format(z[0].dtype))
            # print('åå‘ åµŒå…¥ï¼šé‡‡æ ·çš„z shape is {}:'.format(np.asarray(z).shape))
            print('1!!', x.shape)
            x_l, x_ab, cond, ab_pred = model.prepare_batch(x)
            x_ab_sampled = model.combined_model.module.reverse_sample(list(np.asarray(z)), cond)
            image = data.norm_lab_to_rgb(x_l, x_ab_sampled)
            print('åå‘ åµŒå…¥ï¼šç”Ÿæˆçš„image shape is {}:'.format(image.shape))
            stego_dir = './output/stego_png/k={}/batch={}'.format(args.size_k, batch_idx)
            if not os.path.exists(stego_dir):
                os.makedirs(stego_dir)
            for i in range(image.shape[0]):
                imageio.imwrite(stego_dir+'/{}.png'.format(i), image[i].squeeze().transpose(1, 2, 0))
            # ims.extend(list(image))
            # viz.show_imgs(*ims)

            print('-------' * 10)
            # æ­£å‘ æå–ï¼ˆæ–¹æ³•ï¼šä¿å­˜ä¸ºå›¾ç‰‡ï¼ŒRGBæ•´æ•°å­˜å‚¨ï¼‰
            stego_list = sorted(glob.glob(join(stego_dir, '*.png')))
            stego_data = data.LabColorDataset(stego_list, None)
            stego_loader = DataLoader(stego_data, batch_size=n, shuffle=c.shuffle_val, num_workers=1,
                                     pin_memory=True, drop_last=False)
            for X_lab in stego_loader:
                print('2!!', X_lab.shape)
                L, ab, cnd, _ = model.prepare_batch(X_lab)

                print('condition[0]çš„è¯¯å·®æ˜¯ï¼š', np.average(abs(np.array(cond[0].cpu()) - np.array(cnd[0].cpu()))))
                print('ç°åº¦Lçš„è¯¯å·®æ˜¯ï¼š', np.average(abs(np.array(x_l.cpu()) - np.array(L.cpu()))))
                print('è‰²åº¦x_abçš„è¯¯å·®æ˜¯ï¼š', np.average(abs(np.array(x_ab_sampled.cpu()) - np.array(ab.cpu()))))

                outputs = model.cinn(ab, cnd)
                print('æ­£å‘ æå– ç”±cinnå¾—åˆ°çš„ z(outputs) shape is {}:'.format(np.asarray(outputs).shape))
                break

            # ä¸€å¼ 3*256*256çš„å›¾åƒæ˜¯ 8192= 2*64*64
            # 4å¼ å›¾åƒçš„Z ç»„æˆéƒ¨åˆ†æ˜¯ [4, 4096]ï¼Œ[4, 2048]ï¼Œ[4, 1536]ï¼Œ[4, 512]
            # å¯¹äºä¸€å¼ å›¾ï¼š4096 + 2048 + 1536 + 512 - 2*64*64 = 0  good!!!
            # å‰åZï¼ˆç”±4éƒ¨åˆ†ç»„æˆï¼‰çš„è¯¯å·®ï¼š
            # print('Zç”±4éƒ¨åˆ†ç»„æˆï¼š',z[0].shape,z[1].shape,z[2].shape,z[3].shape)
            # ç”±ç»Ÿè®¡å¾—ï¼ŒZæ˜¯0å‡å€¼1æ–¹å·®çš„ã€‚
            # print('\n', 'outputsçš„å‡å€¼æ˜¯ï¼š', cal_avg_var(outputs)[0])
            # print('outputs[0]çš„æ–¹å·®æ˜¯ï¼š', cal_avg_var(outputs)[1], '\n')
            # np.savetxt('./z[0]-outputs[0].txt', np.array(z[0].cpu()) - np.array(outputs[0].cpu()))

            bitstream2 = extract(outputs, args)
            compare_bitstream(bitstream1, bitstream2, args)
            print('-----end-----' * 7)

        reconZ_relate2which_jpg_is_small(z, outputs, batch_idx, n, args)
        batch_idx += 1
        break